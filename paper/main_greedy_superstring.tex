\documentclass[11pt]{article}
\usepackage{fullpage}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsmath, amsfonts, amssymb, amsthm}

\usepackage{setspace}
\usepackage{relsize}
\usepackage{latexsym}
\usepackage{enumitem}

\usepackage{tikz}
\usetikzlibrary{calc,arrows,shapes,backgrounds,patterns,fit,decorations,decorations.pathmorphing}

\usepackage[colorinlistoftodos]{todonotes}
\usepackage[hidelinks]{hyperref}

\usepackage{algorithm}
\usepackage[noend]{algpseudocode}

\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\newtheorem{proposition}{Proposition}
\newtheorem{claim}{Claim}
\newtheorem{definition}{Definition}
\newtheorem*{statement}{Statement}
\newtheorem*{remark}{Remark}


\DeclareMathOperator{\overlap}{overlap}
\DeclareMathOperator{\pref}{pref}
\DeclareMathOperator{\suff}{suff}
\DeclareMathOperator{\ein}{in}
\DeclareMathOperator{\eout}{out}
\DeclareMathOperator{\bal}{\Delta}
\DeclareMathOperator{\lvl}{level}
\DeclareMathOperator{\defn}{def}
\DeclareMathOperator{\poly}{poly}
\DeclareMathOperator{\inp}{input}
\DeclareMathOperator{\indegree}{indegree}
\DeclareMathOperator{\outdegree}{outdegree}

\renewcommand{\geq}{\geqslant}
\renewcommand{\leq}{\leqslant}
\newcommand{\sedge}[2]{$({\tt #1}, {\tt #2})$}
\newcommand{\cld}{D_{cl}}
\newcommand{\grd}{D_{gr}}
\newcommand{\cldr}[1]{D_{cl}(#1)}
\newcommand{\grdr}[1]{D_{gr}(#1)}
\newcommand{\clgraph}{G_{cl}}
\newcommand{\grgraph}{G_{gr}}


\tikzstyle{hgedge}=[->,gray!30!white]
\tikzstyle{anypath}=[->,dashed]
\tikzstyle{vertex}=[draw,ellipse,inner sep=0.5mm]
\tikzstyle{inputvertex}=[draw,rectangle,inner sep=0.5mm]

\newenvironment{mypic}{\begin{center}\begin{tikzpicture}[>=latex,line width=.3mm]}{\end{tikzpicture}\end{center}}


\begin{document}
%\hrule
%\input pics

\sloppy
\date{}
\title{Collapsing Superstring Conjecture}
\author{}
%\author{
%Alexander Golovnev\thanks{Harvard University.}
%\and
%Alexander~S.~Kulikov\thanks{Steklov Institute of Mathematics at St. Petersburg, Russian Academy of Sciences.}
%\and
%Alexander Logunov\footnotemark[2]
%\and
%Ivan Mihajlin\thanks{University of California San Diego.}
%}
\maketitle

\begin{abstract}
In the Shortest Common Superstring (SCS) problem, one is given a collection of strings, and needs to find a shortest string containing each of them as a substring. SCS admits $2\frac{11}{23}$- and $2\frac{11}{30}$-approximations in polynomial time. While these approximation algorithms and their analyzes are technically involved, the $30$ years old Greedy Conjecture claims that the trivial and efficient Greedy Algorithm gives a $2$-approximation for SCS. The Greedy Algorithm repeatedly merges two strings with the largest intersection into one, until only one string remains.

We develop a graph-theoretic framework for studying approximation algorithms for SCS. In this framework, we give a (stronger) counterpart to the Greedy Conjecture: We conjecture that the presented in this paper Greedy Hierarchical Algorithm gives a $2$-approximation for SCS. This algorithm is almost as simple as the standard Greedy Algorithm, and we suggest a combinatorial approach for proving this conjecture. We support the conjecture by showing that the Greedy Hierarchical Algorithm gives a $2$-approximation in the case when all input strings have length at most $3$ (which until recently had been the only case where the Greedy Conjecture was proven). We also tested our conjecture on tens of thousands of instances of SCS.

Except for its conjectured good approximation ratio, the Greedy Hierarchical Algorithm finds \emph{exact} solutions for the special cases where we know polynomial time (not greedy) exact algorithms: (1) when the input strings form a spectrum of a string (2) when all input strings have length at most $2$.
\end{abstract}

%\tableofcontents

\section{Introduction}
\label{sec:intro}
The {\em shortest common superstring problem} (abbreviated as SCS) is:
given a~set of strings, find a~shortest string that contains all of them as
substrings. This problem finds applications in genome assembly~\cite{waterman1995introduction, pevzner2001eulerian}, and data compression~\cite{GMS1980, phdthesis, storer1987data} (see \cite{gevezes2014shortest, mucha2007tutorial} for an overview of SCS, its applications and algorithms).  SCS is known to be $\mathbf{NP}$-hard~\cite{GMS1980} and even $\mathbf{MAX}$-$\mathbf{SNP}$-hard~\cite{BJLTY1991}, but it admits constant-factor approximation in polynomial time.

The best known approximation ratios are $2\frac{11}{23}$ due to Mucha~\cite{M2013} and $2\frac{11}{30}$ due to Paluch~\cite{P14} (see \cite[Section~2.1]{GKM13} for an overview of the 
previous approximation algorithms
and inapproximability results). While these approximation algorithms use an algorithm for Maximum Weight Perfect Matching as a subroutine, the $30$ years old \emph{Greedy Conjecture}~\cite{storer1987data, TU1988, T1989, BJLTY1991} claims that the trivial \emph{Greedy Algorithm}, whose pseudocode is given in Algorithm~\ref{algo:ga}, is 2-approximate. Ukkonen~\cite{ukkonen1990linear} shows that for a fixed alphabet, the Greedy Algorithm can be implemented in linear time.

\begin{algorithm}[ht]
\label{algo:ga}
\caption{Greedy Algorithm (GA)}
\hspace*{\algorithmicindent} \textbf{Input:} set of strings~${\cal S}$.\\
\hspace*{\algorithmicindent} \textbf{Output:} a~superstring~for $\mathcal{S}$.
\begin{algorithmic}[1]
\While{$\mathcal{S}$ contains at least two strings}
\State extract from $\mathcal{S}$ two strings with the maximum overlap
\State add to $\mathcal{S}$ the shortest superstring of these two strings
\EndWhile
\State return the only string from $\mathcal{S}$
\end{algorithmic}
\end{algorithm}


Blum et al.~\cite{BJLTY1991} prove that the Greedy Algorithm returns a $4$-approximation of SCS, and Kaplan and Shafrir~\cite{KS2005} improve this bound to $3.5$. A slight modification of the Greedy Algorithm gives a $3$-approximation of SCS~\cite{BJLTY1991}, and other greedy algorithms are studied from theoretical~\cite{BJLTY1991,rivals2018superstrings} and practical perspectives~\cite{romero2004experimental, cazaux2018practical}.

It is known that the Greedy Conjecture holds for the case when all input strings have length at most $3$~\cite{TU1988, cazaux20143}, and it was recently shown to hold in the case of string of length $4$~\cite{kulikov2015greedy}. Also, the Greedy Conjecture holds if the Greedy Algorithm happens to merge strings in a particular order~\cite{weinard2006greedy, laube2005conditional}. The Greedy Algorithm gives a $2$-approximation of a different metric called compression~\cite{TU1988}. The compression is defined as the sum of the lengths of all input strings minus the length of a superstring.

%following simple 
%greedy algorithm is 2-approximate: while there are more than two strings 
%in the set, take two of them with the maximum overlap and replace them
%with their shortest superstring.


Most of the approaches for approximating SCS are based on the
{\em overlap graph} or the equivalent \emph{suffix graph}. The suffix graph has input strings as nodes, and a pair of nodes 
is joined by an~arc of weight equal to their suffix (see Section~\ref{sec:def_scs} for formal definitions of overlap and suffix).
SCS is equivalent to the Traveling Salesman Problem (TSP) in the suffix graph. While TSP cannot be approximated within any polynomial time computable function unless $\mathbf{P}=\mathbf{NP}$~\cite{SG1976}, its special case corresponding to SCS can be approximated within a constant factor. We do not know the full characterization of the graphs in this special case, but we know some of its properties: Monge inequality~\cite{monge}, Triple ineqaulity~\cite{weinard2006greedy}. These properties are provably not sufficient for proving Greedy Conjecture~\cite{weinard2006greedy, laube2005conditional}. 

While the overlap and suffix graphs give a~convenient graph structure, our current knowledge of their properties is provably not sufficient for showing strong approximation factors. Thus, the known approximation algorithms (including the Greedy Algorithm) estimate the approximation ratio via the overlap graph, and also separately take into account string properties. The goal of this paper is to develop a simple combinatorial framework which captures all features of the input strings needed for proving approximation ratios of algorithms.

We continue the study of the so-called {\em hierarchical graph}
introduced by Golovnev et al.~\cite{scs_exact}. This graph in a~sense generalizes de~Bruijn graph, it is designed specifically 
for the SCS problem, and contains more useful information about the input strings
than just all pairwise overlaps. We present a simple and natural greedy algorithm
in the hierarchical graph. 
We demonstrate its usefulness by showing that it finds an optimal solution 
in two well-known polynomially solvable special cases: strings of length~$2$ and
a~$k$-spectrum of a~string.

We then conjecture that this greedy algorithm is $2$-approximate. We suggest a combinatorial way of proving this conjecture. For this, we introduce an {\em even stronger} conjecture that we call 
{\em Collapsing Superstring Conjecture}. 
Roughly, it says that it is possible to transform a~doubled optimal 
solution into a~greedy solution. 
The corresponding transformation, that we call {\em collapsing}, 
is just a repeated replacing of two arcs $a\alpha \to a\alpha b \to \alpha b$ 
by two arcs $a\alpha \to \alpha \to \alpha b$ (where $\alpha$ is an arbitrary string). 
We support the Collapsing Superstring Conjecture by 
proving that it holds for the~special case when the input strings have length~3.

%We report on computational experiments that verified the 
%conjecture on many datasets (both hand-crafted and generated randomly
%according to various distributions). 


The Collapsing Superstring Conjecture immediately implies that the Greedy
Hierarchical Algorithm is 2-approximate. Remarkably, it seems to be much
stronger in the following sense. Let $GS$ be the set of arcs of a~greedy
solution and let $DOS$ be the set of arcs of a~collapsed doubled optimal
solution. For proving 2-approximability, it suffices to show that $|GS| \le |DOS|$. 
One way of showing this is to prove that $GS \subseteq DOS$. 
The conjecture, at the same time, states that this inclusion holds with equality.

We implemented the Greedy Hierarchical Algorithm~\cite{github}, and tested our conjectures on tens of thousands of datasets (both hand-crafted and generated randomly according to various distributions). We provide a web interface~\cite{webpage} so that anyone could test the conjectures on arbitrary datasets. The webpage also gives detailed visualizations of how the Greedy Hierarchical and Collapsing algorithms work.

\section{Definitions}
\subsection{Shortest Common Superstring Problem}
\label{sec:def_scs}
%By $u\sqsupset v$ ($u\sqsubset v$) we denote that $u$ is a suffix (prefix) of $v$.
For a string $s$, by $|s|$ we denote the length of $s$. 
For strings~$s$ and~$t$, by $\overlap(s,t)$
we denote the longest suffix of~$s$ that is also 
a~prefix of~$t$. By $\pref(s,t)$
we denote the first $|s|-|\overlap(s,t)|$ symbols of $s$.
Similarly, $\suff(s,t)$ is the last
$|t|-|\overlap(s,t)|$ symbols of~$t$. 
By $\pref(s)$ and $\suff(s)$ we denote, respectively,
the first and the last $|s|-1$ symbols of~$s$. See Figure~\ref{fig:overlap} for a~visual explanation. We also denote the empty string by $\varepsilon$.

If $U$ and $V$ are two multisets, the by $U\sqcup V$ we denote the multiset $W$ such that each $w\in W$ has multiplicity equal to the sum of multiplicities it has in sets $U$ and $V$. For a directed graph $G=(V,E)$, we say that $P$ is a weak path between vertices $u, v\in V$ if replacing all arcs of $G$ with undirected edges produces a graph where $P$ is an undirected path between $u$ and $v$.
\begin{figure}[ht]
\begin{mypic}
\begin{scope}
%\draw[help lines,step=5mm] (0,0) grid (14,3);

\draw (0,2) rectangle (6,2.5);
\draw[step=5mm] (0,2) grid (6,2.5);
\node[left] at (0,2.25) {$s$};
\draw (3,0.5) rectangle (10,1);
\draw[step=5mm] (3,0.5) grid (10,1);
\node[right] at (10,0.75) {$t$};

\foreach \x in {3.25, 3.75, ..., 5.75}
  \draw[gray,thick] (\x,2) -- (\x,1);

\foreach \f/\t/\y/\lab in {0/3/1.5/{\pref(s,t)}, 
3/6/0/{\overlap(s,t)}, 6/10/0/{\suff(s,t)}, 0/5.5/3/\pref(s),
0.5/6/3.5/\suff(s)}
  \path (\f,\y) edge[<->] node[rectangle,inner sep=0.5mm,fill=white] {\strut $\lab$} (\t,\y);
  
\foreach \x/\a in {0/b, 0.5/a, 1/a, 1.5/c, 2/a, 2.5/b, 3/b, 3.5/c, 4/a, 4.5/a, 5/c, 5.5/b}
  \node at (\x+0.25,2.25) {\tt \a};
\foreach \x/\a in {3/b, 3.5/c, 4/a, 4.5/a, 5/c, 5.5/b, 6/a, 6.5/c, 7/a, 7.5/a, 8/a, 8.5/b, 9/c, 9.5/a}
  \node at (\x+0.25,0.75) {\tt \a};
\end{scope}
\end{mypic}
\caption{Pictorial explanations of $\pref$, $\suff$, and $\overlap$ functions.}
\label{fig:overlap}
\end{figure}


Throughout the paper by ${\cal S}=\{s_1, \dots, s_n\}$ we denote
the set of~$n$ input strings. We assume that no input string is a~substring of another (such a~substring can be removed from $\mathcal{S}$ on the preprocessing stage). Note that SCS is a~{\em permutation problem}: to find a~shortest string containing all $s_i$'s in a given order one just
overlaps the strings in this order, see Figure~\ref{fig:permutation}. This simple observation relates SCS to other permutation problems, including different versions of the Traveling Salesman Problem.

\begin{figure}[ht]
\begin{mypic}
%\draw[help lines] (0,0) grid (16,4);

\foreach \x in {0, 2.5, 5.5, 10, 12.5, 16}
  \draw[dashed,gray,thin] (\x,-0.5) -- (\x,4);

\foreach \x/\y/\len/\label in {0/3/5/s_{i_1}, 1/2.5/9/s_{i_2}, 2/2/16/s_{i_3}, 10.5/1/4/s_{i_{n-1}}, 12/0.5/8/s_{i_n}} {
  \draw (\x,\y) rectangle (\x+0.5*\len,\y+0.5);
  \node at (\x+0.25*\len,\y+0.25) {$\label$};
}

\foreach \f/\t/\label in {0/2.5/{s_{i_1}}, 2.5/5.5/{\suff(s_{i_1}, s_{i_2})}, 5.5/10/{\suff(s_{i_2}, s_{i_3})}, 12.5/16/{\suff(s_{i_{n-1}}, s_{i_n})}}
  \path (\f,0) edge[<->] node[rectangle,inner sep=0.5mm,fill=white] {\strut $\label$} (\t,0);

\node at (11,0) {$\dotsb$};
\node at (10.5,1.75) {$\dotsb$};
\end{mypic}
\caption{SCS is a~permutation problem. The length of a~superstring corresponding to a~permutation $(s_{i_1}, \dotsc, s_{i_n})$ is $|s_{i_1}|$ plus the sum of the lengths of suffixes of consecutive pairs of strings.}
\label{fig:permutation}
\end{figure}


\subsection{Hierarchical Graph}
%\begin{definition}[hierarchical graph]
For a~set of strings~${\cal S}$, a~\emph{hierarchical graph} $HG=(V,E)$ is a~weighted directed graph with $V=\{v \colon \text{$v$ is a~substring of some $s \in {\cal S}$}\}$. For every $v \in V,\, v \neq \varepsilon$, the set of arcs~$E$ contains an {\em up-arc} $(\pref(v), v)$ of weight~1 and a {\em down-arc} $(v, \suff(v))$ of weight~0. The meaning of an up-arc is appending one symbol to the end of the current string (and that is why it has weight~1), whereas the meaning of a down-arc is cutting down one symbol from the beginning of the current string.
%\end{definition}
%
Figure~\ref{fig:hgex}(a) gives an example of the hierarchical graph and shows that the terminology of up- and down-arcs comes from placing all the strings of the same length at the same level, where the $i$-th level contains strings of length~$i$.  In all the figures in this paper, the input strings are shown in rectangles, while all other vertices are ellipses.

\newcommand{\we}[4]{
\begin{scope}[xshift=#1mm,yshift=#2mm]
\foreach \n/\x/\y in {aaa/0/3, cae/1/3, aec/3/3, eee/4/3}
  \node[inputvertex] (\n) at (\x,\y) {\tt \n};
%  
\foreach \n/\x/\y in {aa/0/2, ca/1/2, ae/2/2, ec/3/2, ee/4/2, a/1/1, c/2/1, e/3/1}
  \node[vertex] (\n) at (\x,\y) {\tt \n};
%
\node[vertex] (eps) at (2,0) {$\varepsilon$};
%
\foreach \f/\t/\a in {eps/e/10, e/eps/10, eps/c/10, c/eps/10, eps/a/10, a/eps/10, a/aa/10, aa/a/10, aa/aaa/10, aaa/aa/10, c/ca/0, ca/cae/0, cae/ae/0, ae/aec/0, aec/ec/0, ee/eee/10, eee/ee/10, e/ee/10, ee/e/10, ca/a/0, a/ae/0, ae/e/0, e/ec/0, ec/c/0}
  \path (\f) edge[hgedge,bend left=\a] (\t);
  
\node at (2,-1) {(#3)};

#4
\end{scope}
}

\begin{figure}[ht]
\begin{mypic}
\we{0}{0}{a}{}

\we{57}{0}{b}{
\foreach \f/\t/\a in {eps/a/10, a/ae/0, ae/aec/0, aec/ec/0, ec/c/0, c/ca/0, ca/a/0, a/eps/10}
  \path (\f) edge[hgedge,bend left=\a,draw=black,thick] (\t);
}

\we{114}{0}{c}{
\foreach \f/\t/\a in {eps/a/10, a/aa/10, aa/aaa/10, aaa/aa/10, aa/a/10, a/ae/0, ae/aec/0, aec/ec/0, ec/c/0, c/ca/0, ca/cae/0, cae/ae/0, ae/e/0, e/ee/10, ee/eee/10, eee/ee/10, ee/e/10, e/eps/10}
  \path (\f) edge[hgedge,bend left=\a,draw=black,thick] (\t);
}
\end{mypic}
\caption{(a)~Hierarchical graph for the~dataset $\mathcal{S}=\{{\tt aaa}, {\tt cae}, {\tt aec}, {\tt eee}\}$. (b)~The~walk $\varepsilon \to {\tt a} \to {\tt ae} \to {\tt aec} \to {\tt ec} \to {\tt c} \to {\tt ca} \to {\tt a} \to \varepsilon$ has length (or weight)~4 and spells the~string {\tt aeca} of length~4. (c)~An~optimal superstring for~$\mathcal{S}$ is {\tt aaaecaeee}. It has length~9, corresponds to the~permutation $({\tt aaa}, {\tt aec}, {\tt cae}, {\tt eee})$, and defines the~walk of length~9 shown in black.}
\label{fig:hgex}
\end{figure}

What we are looking for in this graph is a shortest
walk from $\varepsilon$ to $\varepsilon$ going
through all the nodes from~$\mathcal{S}$.
It is not difficult to see that the length of a~walk 
from $\varepsilon$ to $\varepsilon$ equals the 
length of the string spelled by this walk. 
This is just because each up-arc has 
weight~$1$ and adds one symbol to 
the current string. See Figure~\ref{fig:hgex}(b) for an~example.
%For example, in the graph of Fiure.~\ref{fig:hgexfirst} 
%a~walk $\varepsilon\to{\tt b}\to{\tt ba}
%\to{\tt bab}\to{\tt ab}\to{\tt abc}
%\to{\tt abca}\to{\tt bca}\to{\tt ca}\to{\tt a}
%\to\varepsilon$ has length $5$ and spells 
%a~string {\tt babca} 
%of length~$5$ in a~natural way.\todo{Update this when you update the figure.}

Hence, what we are looking for in this graph is a~shortest closed walk from $\varepsilon$ to $\varepsilon$ that visits all nodes from~${\cal S}$. Note that a walk may contain repeated nodes and arcs. The multiset of arcs of such a~walk must be Eulerian (each vertex must have the same in- and out-degree, and the set of arcs must be connected). It will prove convenient to define a~{\em solution} in hierarchical graph as an~Eulerian multiset of arcs~$D$ that goes through $\varepsilon$ and all nodes from~${\cal S}$. Given such a~solution~$D$, one can easily recover an Eulerian cycle (that might not be unique). This cycle spells a~superstring of~${\cal S}$ of the same length as~$D$. Figure~\ref{fig:hgex}(c) shows a~solution corresponding to an optimal superstring.

\section{Greedy Hierarchical Algorithm}
%\subsection{Algorithm and Conjecture}
In this section, we present a~greedy algorithm for
finding a~superstring in the hierarchical graph. 
It constructs a~solution~$D$ in a~stingy way. 
Namely, the algorithm only adds arcs to~$D$ 
if it is absolutely necessary: either to balance the degree of a~node or to ensure connectivity 
(as $D$ must be Eulerian). 
More precisely, first it considers the input
strings~${\cal S}$. Since we assume that 
no $s \in {\cal S}$ is a~substring of another 
$t \in {\cal S}$, there is no down-path from~$t$ to~$s$ in $HG_{\cal S}$. 
This means that any walk through $\varepsilon$ and ${\cal S}$ goes through the arcs $\{(\operatorname{pref}(s), s), (s, \operatorname{suff}(s)) \colon s \in {\cal S}\}$. The algorithm adds all of them to~$D$ and starts processing all the nodes level by level, from top to bottom. On each level, we process the nodes in the lexicographic order. If the degree of the current node~$v$ is imbalanced, we balance it by adding an appropriate number of incoming (i.e., $(\pref(v),v)$) or outgoing (i.e., $(v, \suff(v))$) arcs from the previous (i.e., lower) level. In case $v$ is balanced, we just skip it. The only exception when we cannot skip it is when {\em $v$~lies in an Eulerian component and $v$ is the last chance of this component to be connected to the rest of the arcs in~$D$}. We give an~example of such a~situation below. The pseudocode is given in~Algorithm~\ref{algo:gha}. Figure~\ref{fig:hgexa} shows a~few intermediate stages of the algorithm on our working sample dataset.


\begin{algorithm}[ht]
\label{algo:gha}
\caption{Greedy Hierarchical Algorithm (GHA)}
\hspace*{\algorithmicindent} \textbf{Input:} set of strings~${\cal S}$.\\
\hspace*{\algorithmicindent} \textbf{Output:} solution~$D$.
\begin{algorithmic}[1]
\State $HG(V,E) \gets \text{hierarchical graph of ${\cal S}$}$ 
\State\label{alg:gha_init} $D \gets \{(\operatorname{pref}(s), s), (s, \operatorname{suff}(s)) \colon s \in {\cal S}\}$
\For{level $l$ from $\max\{|s| \colon s \in {\cal S}\}$ downto 1}\label{alg:for}
\For{node $v \in V$ with $|v|=l$ in the lexicographic order}
\If{$\operatorname{upper-indegree}(v, D) \neq \operatorname{upper-outdegree}(v, D)$}
\State\label{alg:step6} balance the degree of $v$ in $E$ by adding an appropriate number of lower arcs
\Else
\State\label{alg:else} ${\cal C} \gets \text{weakly connected component of $v$ in $D$}$
\State $u \gets \text{the lexicographically largest string among shortest strings in ${\cal C}$}$
\If{${\cal C}$ is Eulerian, $\varepsilon \not \in {\cal C}$, and $v = u$}
\State\label{alg:last} $D \gets D \cup \{(\pref(v), v), (v, \suff(v))\}$
\EndIf
\EndIf
\EndFor
\EndFor
\State return $D$
\end{algorithmic}
\end{algorithm}

\begin{figure}[ht]
\begin{mypic}
\we{0}{0}{a}{
\foreach \f/\t/\a in {aa/aaa/10, aaa/aa/10, ca/cae/0, cae/ae/0, ae/aec/0, aec/ec/0, ee/eee/10, eee/ee/10}
  \path (\f) edge[hgedge,bend left=\a,draw=black,thick] (\t);
}

\we{57}{0}{b}{
\foreach \f/\t/\a in {aa/aaa/10, aaa/aa/10, ca/cae/0, cae/ae/0, ae/aec/0, aec/ec/0, ee/eee/10, eee/ee/10, aa/a/10, a/aa/10, c/ca/0, ec/c/0, ee/e/10, e/ee/10}
  \path (\f) edge[hgedge,bend left=\a,draw=black,thick] (\t);
}

\we{114}{0}{c}{
\foreach \f/\t/\a in {aa/aaa/10, aaa/aa/10, ca/cae/0, cae/ae/0, ae/aec/0, aec/ec/0, ee/eee/10, eee/ee/10, aa/a/10, a/aa/10, c/ca/0, ec/c/0, ee/e/10, e/ee/10, a/aa/10, aa/a/10, eps/c/10, c/eps/10, e/eps/10, eps/e/10, a/eps/10, eps/a/10}
\path (\f) edge[hgedge,bend left=\a,draw=black,thick] (\t);
}
\end{mypic}
\caption{(a)~After processing the $l=3$ level. (b)~After processing the $l=2$ level. Note that for the node {\tt aa} we add two lower arcs ($({\tt a}, {\tt aa})$ and $({\tt aa}, {\tt a})$) since otherwise the corresponding weakly connected component ($\{{\tt aa}, {\tt aaa}\}$) will not be connected to the rest of the solution. At the same time, when processing the node {\tt ae} we observe that it lies in a~weakly connected component that contains imbalanced nodes ({\tt ca} and {\tt ec}), hence there is no need to add two lower arcs to {\tt ae}. (c)~After processing the $l=1$ level. The resulting solution has length~10 and is, therefore, suboptimal.}
\label{fig:hgexa}
\end{figure}

The advantage of GHA over GA is that GHA is more flexible in the following sense. On every step, GA selects two strings and fixes tightly an order on them. GHA instead works to ensure connectivity. When the resulting set~$D$ is connected, an actual order of input strings will be given by the corresponding Eulerian cycle through~$D$.

We are now ready to state our conjecture about the Greedy Hierarchical Algorithm.
\newtheorem*{ghcc}{Greedy Hierarchical Superstring Conjecture}
\begin{ghcc}
GHA is 2-approximate.
\end{ghcc}
In Appendix~\ref{app:a} we show the behavior of GHA on various datasets. In particular, we prove that GHA solves \emph{exactly} two well-known polynomially solvable special cases of SCS. 
%In the next section, we suggest a~way of proving the conjecture by connecting GHA to another algorithm.

\section{Collapsing Algorithm}
In this section, we suggest a way to prove the Greedy Hierarchical Superstring Conjecture. We define a transformation of a superstring $s$ into a different superstring $s'$ of the same set of strings such that $|s'|\le|s|$. This transformation is done by the Collapsing Algorithm in the hierarchical graph. Informally, the Collapsing Algorithm removes some of the ``redundancies'' in a superstring. We believe that if one takes \emph{any} superstring $s$ of a set of strings ${\cal S}$, then concatenates two copies of $s$, and applies the Collapsing Algorithm, then one always gets exactly the set of arcs chosen by the Greedy Hierarchical Algorithm. We call this the Collapsing Superstring Conjecture. If it is true, then for $s$ equal to an optimal superstring, we get a proof of the Greedy Hierarchical Conjecture. Thus, the Collapsing Superstring Conjecture implies the Greedy Hierarchical Superstring Conjecture. 

Moreover, if the Collapsing Superstring Conjecture is true, then it gives an alternative simple $2$-approximate algorithm for SCS. Indeed, one can take any trivial solution (for example, concatenate all the input strings), then double this solution, and apply the simple Collapsing Algorithm. This will result in a solution which is no longer than two optimal solutions.

In Section~\ref{sec:alg_conj} we give all formal definitions and algorithms. In Sections~\ref{subsec:scs3}--\ref{sec:proof2} we support the conjecture by proving its special case for strings of length~3. We have verified the conjecture on various datasets, and we invite the reader to see its visualizations and to check the conjecture on arbitrary datasets at the webpage~\cite{webpage}.

\subsection{Algorithm and Conjecture}
\label{sec:alg_conj}
The idea of the Collapsing Algorithm is the following. 
We start with any solution~$D$ in the hierarchical graph. 
We double every arc of~$D$ (note that $D$ remains a~solution). What we do next can be informally described as follows:
\begin{enumerate}
\item Imagine that the arcs of~$D$ is a~circular thread, and that there is a~nail in every node~$s \in {\cal S}$.
\item We apply gravitation to the thread, i.e., we replace every pair of arcs $(\pref(v), v)$, $(v, \suff(v))$ 
with a~pair $(v, \pref(\suff(v)))$, $(\pref(\suff(v)), \suff(v))$, where $a$ and $b$ are symbols and $s$ is a~string. We call this {\em collapsing}, see Figure~\ref{fig:collapsing}.
\end{enumerate}
Formally, after doubling every arc of~$D$, we start processing the nodes of the hierarchical graph level by level in the descending order, and in the lexicographic order on every level. If for the current node~$v$ there is a~pair of arcs $(\pref(v), v), (v, \suff(v)) \in D$, we replace it by a~pair of arcs $(\pref(v), \pref(\suff(v))), (\pref(\suff(v)))$ if $D$~remains to be a~solution (i.e., it is still connected). There is one exception for this: if $|v|=1$, then $\pref(\suff(v))$ is undefined and we just remove the pair of arcs. 
A~formal pseudocode of this collapsing procedure is given in Algorithm~\ref{alg:collapse}. This way, the algorithm drops down all arcs of the doubled set~$D$ that are not needed for connectivity. See Algorithm~\ref{alg:ca} for a~formal pseudocode.

\begin{figure}[ht]
\begin{mypic}
\begin{scope}[minimum size=6mm]
%\draw[help lines] (0,0) grid (14,3);
\node[vertex] (a) at (0, 1.5) {$\pref(v)$};
\node[vertex,inner sep=1mm] (b) at (1.5, 2.5) {$v$};
\node[vertex] (c) at (3, 1.5) {$\suff(v)$};
\node[vertex] (d) at (1.5, 0.5) {$ \pref(\suff(v))$};
\draw[->,dashed] (a) -- (b);
\draw[->,dashed] (b) -- (c);
\draw[->] (a) -- (d);
\draw[->] (d) -- (c);

\begin{scope}[xshift=80mm]
\node[vertex] (a) at (0, 1.5) {\tt aba};
\node[vertex,inner sep=1mm] (b) at (1.5, 2.5) {\tt abac};
\node[vertex] (c) at (3, 1.5) {\tt bac};
\node[vertex] (d) at (1.5, 0.5) {\tt ba};
\draw[->,dashed] (a) -- (b);
\draw[->,dashed] (b) -- (c);
\draw[->] (a) -- (d);
\draw[->] (d) -- (c);
\end{scope}
\end{scope}
\end{mypic}
\caption{Collapsing a~pair of arcs is replacing a~pair of dashed arcs with a~pair of solid arcs: general case (left) and example (right). The~``physical meaning'' of this transformation is that to get {\tt bac} from {\tt aba} one needs to cut~{\tt a} from the beginning and append~{\tt c} to the end and these two operations commute.}
\label{fig:collapsing}
\end{figure}

\begin{algorithm}[ht]
\caption{Collapse}\label{alg:collapse}
\hspace*{\algorithmicindent} \textbf{Input:} hierarchical graph $HG(V,E)$, solution $D$, node $v \in V$.
%\hspace*{\algorithmicindent} \textbf{Output:} a~superstring of~${\cal S}$ as a~path $D$~in the hierarchical graph.
\begin{algorithmic}[1]
\If{$(\pref(v), v), (v, \suff(v)) \in D$}
\State $D \gets D \setminus \{(\pref(v), v), (v, \suff(v))\}$
\If{$|v| > 1$}
\State $D \gets D \cup \{(\pref(v), \pref(\suff(v))), (\pref(\suff(v)), \suff(v))\}$
\EndIf
\EndIf
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[ht]
\caption{Collapsing Algorithm (CA)}
\label{alg:ca}
\hspace*{\algorithmicindent} \textbf{Input:} hierarchical graph $HG(V,E)$, solution $D$.\\
\hspace*{\algorithmicindent} \textbf{Output:} solution $D'\colon |D'|\leq|D|$
% a~superstring of~${\cal S}$ as a~path $D$~in the hierarchical graph.
\begin{algorithmic}[1]
\For{level~$l$ in $HG$ in descending order}
\For{all $v \in V(HG)$ s.t. $|v|=\text{\textsl{level}}$ in lexicographic order:}
\While{$(\pref(v), v), (v, \suff(v)) \in D$ and collapsing it does not make~$D$ disconnected}
\State $\text{\sc Collapse}(HG(V,E), D, v)$
\EndWhile
\EndFor
\EndFor
\State return $D$
\end{algorithmic}
\end{algorithm}

When $l>1$, the collapsing procedure does not change the total length of~$D$. 
What one normally sees at the beginning of the
$l=1$ iteration is a~solution with many 
redundant pairs of arcs of the form $(a, \varepsilon)$, $(\varepsilon, a)$. It is exactly this stage of the algorithm where the total length of~$D$ is decreased by the collapsing procedure. See Figures~\ref{fig:coll} and~\ref{fig:collnaive} in Appendix~\ref{app:a} for examples of applying the Collapsing Algorithm in the cases where~$D$ is an optimal and naive solution, respectively.


\newtheorem*{scs}{Collapsing Superstring Conjecture}
\begin{scs}
For any set of strings ${\cal S}$ and for any superstring $C$ of ${\cal S}$, 
\begin{align*}
CA(HG({\cal S}), C \sqcup C) = GHA({\cal S}) \; .
\end{align*}
%Let ${\cal S}$ be a set of strings, let $HG=HG(V, E)$ be its hierarchical graph, let $C\subseteq E$ be a multiset of edges corresponding to a superstring of ${\cal S}$, and let $D=C\sqcup C$. Then $CA(HG, D)$ returns the same multiset of edges as $GHA({\cal S})$.
\end{scs}


\subsection{Proof of the Special Case: Strings of Length~3}\label{subsec:scs3}
In Sections~\ref{subsec:scs3}--\ref{sec:proof2} we prove the Collapsing Superstring Conjecture for strings of length at most~$3$.

The Collapsing Algorithm (CA) starts with $D$ equal to a doubled (arbitrary) solution, and the Greedy Hierarchical Algorithm (GHA) starts with epmty $D=\emptyset$. Then both algorithms consider all vertices of the hierarchical graph $HG=(V, E)$ in the same order (descending order of the levels, lexicographic order within a level). Let $s_0$ be the first vertex considered by CA and GHA ($s_0$ corresponds to an input string). For a vertex $s$, by $V(s)$ we denote the set of vertices considered by the algorithms no later than the vertex $s$ (including the vertex $s$: $s\in V(s)$).

Both algorithms continiously change their partial solutions $D$. By $\cld{}$ and $\grd{}$ we denote the set of arcs included in the partial solutions $D$ of the algorithms CA and GHA right before they start examining the vertex $s$. Let $\clgraph = (V, \cld), \grgraph = (V, \grd)$, where $V$ is the set of vertices of the hierarchical graph $HG$. 

Finally, for CA we define the set $\cldr{s}$, consisting of arcs of $\cld{}$ which are incident to at least one vertex from $ V (s) \setminus \{s \} $ (recall that $\cld{}$ is the set of arcs strictly before the examination of the vertex $s$). For convenience, for GHA we define $\grdr{s}$ in the same way, but note that since GHA always adds arcs adjacent to the vertex it is currently considering, $\grdr{s}=\grd$.\footnote{On the other hand, $\cld$ does not necessarily equal $\cldr{s}$, because $\cld{}$ initially consists of arcs connecting all vertices from $ {\cal S} $ to $\varepsilon$.}

Let us sort all vertices of $V$ in the order in which the two algorithms process them, and let $s$ and $t$ be two consecutive vertices in this order. Now look at the two algorithms processing the vertex $s$. CA and GHA both only change arcs below $s$. Since $\cld{t}$ and $\grd{t}$ only include the arcs incident to vertices from $V(t)$, the following holds for both algorithms:
\begin{equation}
\label{eqn:stepcase}
    D(t) = D(s) \sqcup \bigsqcup_{i=1}^{a} (\pref(s), s) \sqcup \bigsqcup_{j=1}^{b} (s, \suff(s))
\end{equation}
for some non-negative integers $ a $ and $ b $.

In Sections~\ref{sec:proof1}--\ref{sec:proof2} we will prove the following lemma.
\begin{lemma}
\label{lem:technical}
Let ${\cal S}$ be a set of strings of length at most $3$. For each vertex $ s $ at a level at least $1$, if the collapsing algorithm after its examination leaves $ a $ arcs $ (\pref (s), s) $ and $ b$ arcs $ (s, \suff(s) ) $, and the greedy algorithm leaves $ a_{gr} $ and $ b_{gr} $ arcs, respectively, then $ a = a_{gr}, b = b_{gr} $.
\end{lemma}

Now we are ready to finish the proof of Collapsing Superstring Conjecture for strings of length at most $3$. Note that this also implies that the Greedy Hierarchical Superstring Conjecture holds for the case of strings of length at most $3$.

\begin{theorem}
\label{thm:main}
For any set ${\cal S}$ of strings of length at most $3$ and for any superstring $C$ of ${\cal S}$, 
\begin{align*}
CA(HG({\cal S}), C \sqcup C) = GHA({\cal S}) \; .
\end{align*}
\end{theorem}

\begin{proof}
We will prove that
\begin{align*}
\forall s \in V\colon\, \cldr{s}=\grdr{s} \; .
\end{align*}
For $s=\varepsilon$, this statement implies the Collapsing Superstring Conjecture, as it asserts that the two algorithms end up with the same multiset of arcs. 

We prove this statement by induction on $s$, where $s$ starts with $s_0$ and goes through all the vertices of $HG$ in the same order as CA and GHA. The base case $s=s_0$ of the induction argument follows trivially from the definition: $\cldr{s_0}=\grdr{s_0}=\emptyset$. And the induction step is proven in Lemma~\ref{lem:technical}.
\end{proof}
\input proof1
\input proof2


\section{Further Directions and Open Problems}
One natural open problem is to prove the Collapsing Superstring Conjecture.
It would also be interesting to find other applications of the 
hierarchical graphs. We list two such potential applications below.
\begin{description}
\item[Genome assembly.] As we illustrated, the hierarchical graph in a~sense
generalizes de Bruijn graph. The latter one is heavily used
in genome assembly~\cite{pevzner2001eulerian}.
Can one adopt the hierarchical graph for this task? For this, one
would need to come up with a~compact representation of the graph
(as datasets in genome assembly are massive) as well as with a~way of
handling errors in the input data. Cazaux and Rivals~\cite{cazaux2018hierarchical} propose a linear-space counterpart of the hierarchical graph.

\item[Exact algorithms.] Can one use hierarchical graphs to solve SCS exactly in time $(2-\varepsilon)^n$?
It was shown in Section~\ref{sec:intro} that the SCS problem is a special case of the Traveling Salesman Problem. The best known exact algorithms for Traveling Salesman run in time $2^n \poly(|\inp|)$~\cite{B1962, HK1971, KGK1977, K1982, BF1996}. These algorithms stay the best known for the SCS problem as well. The hierarchical graphs were introduced~\cite{scs_exact} for an algorithm solving SCS on strings of length at most $r$ in time $(2-\varepsilon)^n$ (where $\varepsilon$ depends only on $r$). Can one use the hierarchical graph to solve exactly the general case of SCS in time $(2-\varepsilon)^n$ for a constant $\varepsilon$?
\end{description}

\bibliographystyle{alpha}
\bibliography{main}

\appendix
\section{Greedy Hierarchical Algorithm. Special Cases}
\label{app:a}
\subsection{Strings of Length~2}
Gallant et al.~\cite{GMS1980} show that SCS on strings of length $3$ is $\mathbf{NP}$-hard, but SCS on strings of length at most $2$ is solvable in polynomial time. In this section we show that GHA finds an optimal solution in this case as well. We note that the standard Greedy Algorithm does not necessarily find an optimal solution in this case. For example, if ${\cal S}=\{ab, ba, bb\}$, the Greedy Algorithm may first merge $ab$ and $ba$, which would lead to a suboptimal solution $ababb$. 

First, we can assume that all input strings from ${\cal S}$ have length exactly $2$. Indeed, since we assume that no input string is a substring of another input string, all strings of length $1$ are unique characters which do not appear in other strings. Take any such $s_i$ of length $1$. The optimal superstring length for ${\cal S}$ is $k$ if and only if the optimal superstring length for ${\cal S}\setminus\{s_i\}$ is $k-1$. The Hierarchical Greedy Algorithm shows the same behavior. In Step~\ref{alg:gha_init}, GHA will include the arcs $(\varepsilon, s_i), (s_i, \varepsilon)$ in the solution, and it will never touch the vertex $s_i$ again (because it is balanced and connected to $\varepsilon$). Thus, $s_i$ adds $1$ to the length of the Greedy Hierarchical Superstring as well. By the same reasoning, we can assume that each string of length two is primitive, i.e., contains two distinct characters.

When considering primitive strings ${\cal S}=\{s_1,\ldots,s_n\}$ of length exactly $2$, it is convenient to introduce the following directed graph $G=(V, E)$, where $V$ contains a vertex for every symbol which appears in strings from ${\cal S}$. The graph has $|E|=n$ arcs corresponding to $n$ input strings: for every string $s_i=ab$, there is an arc from $a$ to $b$. It is known~\cite{GMS1980} that the length of an optimal superstring in this case is $n+k$ where $k$ is the minimum number such that $E$ can be decomposed into $k$ directed paths, or, equivalently:
\begin{proposition}[\cite{GMS1980}]
Let $G$ be the graph defined above, and let $G_1=(V_1,E_1),\ldots,G_c=(V_c,E_c)$ be its weakly connected components. Then the length of an optimal superstring is
\begin{align}
\label{eq:gms}
n + \sum_{i=1}^{c} {\max\left( 1, \sum_{v \in V_i}{ \frac{ |\indegree(v) - \outdegree(v)|}{2} }\right)} \; .
\end{align}
\end{proposition}

We will now show that in this case, GHA finds essentially the same solution.

\begin{lemma}
Let ${\cal S}=\{s_1,\ldots,s_n\}$ be a set of strings of length at most $2$, and let $s$ be an optimal superstring for ${\cal S}$. Then $GHA({\cal S})$ returns a~superstring of length~$|s|$. 
\end{lemma}

\begin{proof}
We showed above that we can only consider the case of $n$ primitive strings $\{s_1,\ldots,s_n\}$ of length exactly $2$. For $1\leq i\leq n$, let $s_i=a_i b_i$, where $a_i\neq b_i$. Consider the partial greedy hierarchical solution $D$ after the Step~\ref{alg:gha_init} of the GHA algorithm: $D=\{(a_i, a_ib_i), (a_ib_i, b_i): 1\leq i\leq n \}$. (We abuse notation by identifying the set of arcs $D$ with the graph induced by $D$.) This partial solution has $n$ up-arcs, so its current weight is $n$. 

Note that by the definition of the graph $G$ above, $G$ contains an arc $(a, b)$ if and only if $D$ has the arcs $(a, ab)$ and $(ab, b)$ of the graph HG. Thus, the indegree (outdegree) of a vertex $a$ in $G$ equals the indegree (outdegree) of the vertex $a$ in the partial solution $D$. Also, two vertices $a$ and $b$ of $G$ belong to one weakly connected component in $G$ if and only if they belong to one weakly connected component in $D$. Therefore, the expression~\ref{eq:gms} in $G$ has the same value in the partial solution graph $D$. (Indeed, the vertices corresponding to strings of length $2$ are balanced and do not form weakly connected components.) 

Now we proceed to Steps~\ref{alg:for}--\ref{alg:last} of GHA. GHA will go through all strings of length $1$, and add $|\indegree(v) - \outdegree(v)|$ arcs for each unbalanced vertex $v$. The Steps~\ref{alg:else}--\ref{alg:last} ensure that each weakly connected component adds at least a pair of arcs. Since exactly a half of added arcs are up-arcs, we have increased the weight of the partial solution $D$ by
\begin{align*}
\sum_{i=1}^{c} {\max\left( 1, \sum_{v \in V_i}{ \frac{ |\indegree(v) - \outdegree(v)|}{2} }\right)} \; .
\end{align*}
\end{proof}

\subsection{Spectrum of a~String}
By a~$k$-spectrum of a~string $s$ 
(of length at least~$k$)
we call a~set of all substrings of~$s$ of length~$k$.
Pevzner et al.~\cite{pevzner2001eulerian} give a polynomial time exact algorithm for the case when the input strings form a spectrum of an unknown string. We show that GHA also finds an optimal solution in this case.

\begin{lemma}
Let ${\cal S}=\{s_1,\ldots,s_n\}$ be a~$k$-spectrum of an unknown string~$s$. Then $GHA({\cal S})$ returns a~superstring of length at most~$|s|$.
\end{lemma}

\begin{proof}
Since $s$ has $n$ distinct substrings of length $k, \, |s|\geq n+k-1$. We will show that GHA finds a superstring of length $n+k-1$. After Step~\ref{alg:gha_init} of GHA, the partial solution $D = \{(\operatorname{pref}(s), s), (s, \operatorname{suff}(s)) \colon s \in {\cal S}\}$. In particular, $D$ is of weight $n$. For $1\leq i\leq k-1$, let $u_{i}$ be the first $i$ symbols of $s$, and let $v_{i}$ be the last $i$ symbols of $s$. Note that $u_{k-1}$ and $v_{k-1}$ are the only unbalanced vertices of the partial solution $D$ after Step~\ref{alg:gha_init}: all other strings of length $k-1$ appear equal number of times as prefixes and suffixes of strings from ${\cal S}$. Therefore, while processing the level $\ell=k-1$, GHA will add one arc to each of the vertices $u_{k-1}$ and $v_{k-1}$, and will not add arcs to other strings of length $k-1$. 

In general, while processing the level $\ell=i$, GHA adds one up-arc to $u_i$ and one down-arc to $v_i$. In order to show this, we consider two cases. If $u_i \neq v_i$, then $u_i$ has an incoming arc from the previous step and does not have outgoing arcs, therefore GHA adds an up-arc to $u_i$ in Step~\ref{alg:step6}. Similarly, GHA adds a down-arc from $v_i$. Note that there are no other strings of length $i<k-1$ in the partial solution, so the algorithm moves to the next level. In the case when $u_i=v_i$, we have that all vertices are balanced, but the string $u_i$ is now the shortest string in this only connected component ${\cal C}$ of the graph. Therefore, for $i>0$ we have $\varepsilon\not\in{\cal C}$, and GHA adds an up- and down-arc to $u_i$ in Step~\ref{alg:last}. 

We just showed that GHA solution for a $k$-spectrum of a string has the initial set of arcs  $D = \{(\operatorname{pref}(s), s), (s, \operatorname{suff}(s)) \colon s \in {\cal S}\}$, and also the arcs $\{ (u_{i-1}, u_{i}), (v_i, v_{i-1})\colon 1\leq i\leq k-1 \}$. Thus, the total number of up-arcs (and the weight of the solution) is $n+k-1$.
\end{proof}

\subsection{Tough Dataset}
There is a~well-known dataset consisting of just three strings where the classical greedy algorithm produces a~superstring that is almost twice longer than an optimal one: $s_1={\tt cc}({\tt ae})^n$, $s_2=({\tt ea})^{n+1}$, $s_3=({\tt ae})^n{\tt cc}$. Since $\overlap(s_1, s_3)=2n$,
 while $\overlap(s_1,s_2)=\overlap(s_2,s_3)=2n-1$, the greedy algorithm produces a~permutation $(s_1, s_3, s_2)$ (or $(s_2,s_1,s_3)$). I.e., by greedily taking the massive overlap of length $2n$ it loses the possibility to insert $s_2$ between $s_1$ and $s_3$ and to get two overlaps of size $2n-1$. The resulting superstring has length $4n+6$. At the same time, the optimal superstring corresponds to the permutation $(s_1,s_2,s_3)$ and has length $2n+8$.
 
The algorithm GHA makes a~similar mistake on this dataset, see Figure~\ref{fig:tough}. When processing the node $({\tt ea})^n$, GHA does not add two lower arcs to it and misses a~chance to connect two components. It is then forced to connect these two components through~$\varepsilon$. This example shows that GHA also does not give a better than $2$-approximation for SCS.

%\newcommand{\ged}[3]{
%\begin{scope}[xshift=#1mm]
%\foreach \n/\x/\y in {ccae/0.625/4, aecc/3.125/4, eaea/5.625/4}
%  \node[inputvertex] (\n) at (\x,\y) {\tt \n};
%\foreach \n/\x/\y in {cca/0/3, cae/1.25/3, aec/2.5/3, ecc/3.75/3, eae/5/3, aea/6.25/3, cc/1.5/2, ca/2.5/2, ae/3.5/2, ec/4.5/2, ea/5.5/2, c/2.5/1, a/3.5/1, e/4.5/1}
%  \node[vertex] (\n) at (\x,\y) {\tt \n};
%\node[vertex] (eps) at (3.5,0) {$\varepsilon$};
%\node at (3.5,-1) {(#2)};
%
%\foreach \f/\t/\a in {eps/c/10, c/eps/10, eps/a/10, a/eps/10, eps/e/10, e/eps/10, c/cc/10, cc/c/10, c/ca/0, ca/a/0, a/ae/0, ae/e/0, e/ec/0, ec/c/0, e/ea/0, ea/a/0, cc/cca/0, cca/ca/0, ca/cae/0, cae/ae/0, ae/aec/0, aec/ec/0, ec/ecc/0, ecc/cc/0, ea/eae/0, eae/ae/0, ae/aea/0, aea/ea/0, cca/ccae/0, ccae/cae/0, aec/aecc/0, aecc/ecc/0, eae/eaea/0, eaea/aea/0}
%  \path (\f) edge[hgedge,bend left=\a] (\t);
%
%#3
%\end{scope}
%}
% 
%\begin{figure}
%\begin{mypic}
%\ged{0}{a}{
%\foreach \f/\t/\a in {eps/c/10, c/cc/10, cc/cca/0, cca/ccae/0, ccae/cae/0, cae/ae/0, ae/e/0, e/ea/0, ea/eae/0, eae/eaea/0, eaea/aea/0, aea/ea/0, ea/a/0, a/ae/0, ae/aec/0, aec/aecc/0, aecc/ecc/0, ecc/cc/0, cc/c/10, c/eps/10}
%  \path (\f) edge[hgedge,bend left=\a,draw=black,thick] (\t);
%}
%
%\ged{80}{b}{}
%\end{mypic}
%\caption{(a)~A~solution of length~10 corresponding to an optimal superstring {\tt ccaeaeaecc}. (b)~A~solution of length~11 constructed by GHA.}
%\label{fig:tough}
%\end{figure}

\newcommand{\ged}[2]{
\tikzstyle{t}=[vertex,draw=black]
\tikzstyle{p}=[->,decorate,decoration=snake,bend left=10]
\begin{scope}[yshift=#1mm]
\node[inputvertex] (ccaen) at (0,5) {{\tt cc}({\tt ae})$^n$};
\node[inputvertex] (eann) at (10,5) {({\tt ea})$^{n+1}$};
\node[inputvertex] (aencc) at (4.5,5) {({\tt ae})$^n${\tt cc}};
\node[t] (ccaena) at (-1,4) {\tt cc(ae)$^{n-1}$a};
\node[t] (caen) at (1.5,4) {\tt c(ae)$^{n}$};
\node[t] (eane) at (9,4) {\tt (ea)$^{n}$e};
\node[t] (aean) at (11,4) {\tt a(ea)$^{n}$};
\node[t] (aenc) at (3.5,4) {\tt (ae)$^{n}$c};
\node[t] (eaencc) at (6,4) {\tt e(ae)$^{n-1}$cc};
\node[t] (ccaenn) at (1,3) {\tt cc(ae)$^{n-1}$};
\node[t] (aen) at (3.5,3) {\tt (ae)$^{n}$};
\node[t] (ean) at (10,3) {\tt (ea)$^{n}$};
\node[t] (aenncc) at (6,3) {\tt (ae)$^{n-1}$cc};
\node[t] (eaenn) at (3.5,2) {\tt e(ae)$^{n-1}$};
\node[t] (aeann) at (7,2) {\tt a(ea)$^{n-1}$};
\node[t] (eps) at (5,0) {$\varepsilon$};

\foreach \f/\t in {ccaena/ccaen, ccaen/caen, eane/eann, eann/aean, aenc/aencc, aencc/eaencc, ccaenn/ccaena, caen/aen, ean/eane, aean/ean, aen/aenc, eaencc/aenncc, ean/aeann, eaenn/ean}
  \draw[->] (\f) -- (\t);
  
\path (eps) edge[p] (ccaenn);
\path (aenncc) edge[p] (eps);

#2
\end{scope}
}

 
\begin{figure}
\begin{mypic}
\ged{0}{
\foreach \f/\t in {aeann/aen, aen/eaenn}
  \draw[->] (\f) -- (\t);
}

\ged{-60}{
\path (eps) edge[p] (eaenn);
\path (aeann) edge[p] (eps);
}
\end{mypic}
\caption{Top: optimal solution for the dataset $\{ {\tt cc}({\tt ae})^n, ({\tt ea})^{n+1}, ({\tt ae})^n{\tt cc} \}$. Bottom: solution constructed by GHA.}
\label{fig:tough}
\end{figure}

%\clearpage
%\section{Collapsing Algorithm. Examples}
%\label{app:b}
\begin{figure}[h]
\begin{mypic}
\we{0}{0}{a}{
\foreach \f/\t/\a in {eps/a/10, eps/a/20, 
a/aa/10, a/aa/20, 
aa/aaa/10, aa/aaa/20,
aaa/aa/10, aaa/aa/20,
aa/a/10, aa/a/20, 
a/ae/0, a/ae/10,
ae/aec/0, ae/aec/10,
aec/ec/0, aec/ec/10,
ec/c/0, ec/c/10,
c/ca/0, c/ca/10,
ca/cae/0, ca/cae/10,
cae/ae/0, cae/ae/10,
ae/e/0, ae/e/10,
e/ee/10, e/ee/20,
ee/eee/10, ee/eee/20,
eee/ee/10, eee/ee/20,
ee/e/10, ee/e/20,
e/eps/10, e/eps/20}
  \path (\f) edge[hgedge,bend left=\a,draw=black,thick] (\t);
}

\we{57}{0}{b}{
\foreach \f/\t/\a in {eps/a/10, eps/a/20, 
a/aa/10, a/aa/20, a/aa/30, aa/a/30,
aa/aaa/10,
aaa/aa/10,
aa/a/10, aa/a/20, 
a/ae/0, a/ae/10,
ae/aec/0, ae/e/20,
aec/ec/0, e/ec/0,
ec/c/0, ec/c/10,
c/ca/0, c/ca/10,
ca/cae/0, ca/a/0, a/ae/20,
cae/ae/0,
ae/e/0, ae/e/10,
e/ee/10, e/ee/20, e/ee/30,
ee/eee/10,
eee/ee/10,
ee/e/10, ee/e/20, ee/e/30,
e/ee/30,
e/eps/10, e/eps/20}
  \path (\f) edge[hgedge,bend left=\a,draw=black,thick] (\t);
}

\we{114}{0}{c}{
\foreach \f/\t/\a in {
eps/a/10, eps/a/20, eps/a/30, eps/a/40, a/eps/10, a/eps/20,
a/aa/10,
aa/aaa/10,
aaa/aa/10,
aa/a/10, 
a/ae/0, a/ae/10,
ae/aec/0, ae/e/20,
aec/ec/0, e/ec/0,
ec/c/0, ec/c/10,
c/ca/0, c/ca/10,
ca/cae/0, ca/a/0, a/ae/20,
cae/ae/0,
ae/e/0, ae/e/10,
e/ee/10, e/ee/20, e/ee/30,
ee/eee/10,
eee/ee/10,
ee/e/10, 
ee/e/20,
ee/e/30,
e/ee/30,
e/eps/10, e/eps/20}
  \path (\f) edge[hgedge,bend left=\a,draw=black,thick] (\t);
}

\we{0}{-55}{d}{
\foreach \f/\t/\a in {
eps/a/10, eps/a/20, eps/a/30, eps/a/40, 
a/eps/10, a/eps/20, a/eps/30, a/eps/40, a/eps/50,
a/aa/10,
aa/aaa/10,
aaa/aa/10,
aa/a/10, 
ae/aec/0,
aec/ec/0, e/ec/0,
ec/c/0, ec/c/10,
c/ca/0, c/ca/10,
ca/cae/0, ca/a/0,
cae/ae/0,
e/ee/10, e/ee/20, e/ee/30,
ee/eee/10,
eee/ee/10,
ee/e/10, ee/e/20, ee/e/30,
e/ee/30,
e/eps/10, e/eps/20, e/eps/30,
eps/e/10, eps/e/20, eps/e/30}
  \path (\f) edge[hgedge,bend left=\a,draw=black,thick] (\t);
}

\we{57}{-55}{e}{
\foreach \f/\t/\a in {
eps/a/10, eps/a/20, eps/a/30, eps/a/40, eps/a/50,
a/eps/10, a/eps/20, a/eps/30, a/eps/40, a/eps/50,
a/aa/10,
aa/aaa/10,
aaa/aa/10,
aa/a/10, 
ae/aec/0,
aec/ec/0, e/ec/0,
ec/c/0, ec/c/10,
c/ca/0,
ca/cae/0,
cae/ae/0,
e/ee/10, e/ee/20, e/ee/30,
ee/eee/10,
eee/ee/10,
ee/e/10, ee/e/20, ee/e/30,
e/ee/30,
e/eps/10, e/eps/20, e/eps/30,
eps/e/10, eps/e/20, eps/e/30,
c/eps/10}
  \path (\f) edge[hgedge,bend left=\a,draw=black,thick] (\t);
}

\we{114}{-55}{f}{
\foreach \f/\t/\a in {
eps/a/10, eps/a/20, eps/a/30, eps/a/40, eps/a/50,
a/eps/10, a/eps/20, a/eps/30, a/eps/40, a/eps/50,
a/aa/10,
aa/aaa/10,
aaa/aa/10,
aa/a/10, 
ae/aec/0,
aec/ec/0,
ec/c/0,
c/ca/0,
ca/cae/0,
cae/ae/0,
e/ee/10, e/ee/20, e/ee/30,
ee/eee/10,
eee/ee/10,
ee/e/10, ee/e/20, ee/e/30,
e/ee/30,
e/eps/10, e/eps/20, e/eps/30, e/eps/40,
eps/e/10, eps/e/20, eps/e/30,
c/eps/10, eps/c/10}
  \path (\f) edge[hgedge,bend left=\a,draw=black,thick] (\t);
}

\we{0}{-110}{g}{
\foreach \f/\t/\a in {aa/aaa/10, aaa/aa/10, ca/cae/0, cae/ae/0, ae/aec/0, aec/ec/0, ee/eee/10, eee/ee/10, aa/a/10, a/aa/10, c/ca/0, ec/c/0, ee/e/10, e/ee/10, a/aa/10, aa/a/10, eps/c/10, c/eps/10, 
e/eps/10, eps/e/10, 
e/eps/20, eps/e/20,
e/eps/30, eps/e/30,
e/eps/40, eps/e/40,
e/eps/50, eps/e/50,
a/eps/10, eps/a/10,
a/eps/20, eps/a/20,
a/eps/30, eps/a/30,
a/eps/40, eps/a/40,
a/eps/50, eps/a/50}
\path (\f) edge[hgedge,bend left=\a,draw=black,thick] (\t);
}

\we{57}{-110}{h}{
\foreach \f/\t/\a in {aa/aaa/10, aaa/aa/10, ca/cae/0, cae/ae/0, ae/aec/0, aec/ec/0, ee/eee/10, eee/ee/10, aa/a/10, a/aa/10, c/ca/0, ec/c/0, ee/e/10, e/ee/10, a/aa/10, aa/a/10, eps/c/10, c/eps/10, 
e/eps/10, eps/e/10, 
a/eps/10, eps/a/10}
\path (\f) edge[hgedge,bend left=\a,draw=black,thick] (\t);
}

\end{mypic}
\caption{Stages of applying the Collapsing Algorithm to the dataset $\{{\tt aaa}, {\tt cae}, {\tt aec}, {\tt eee}\}$ and its \textbf{optimal} solution. (a)~We start by doubling every arc of the optimal solution from Figure~\ref{fig:hgex}(c). 
(b)~After collapsing all nodes at level $l=3$. 
(c)~After processing the node {\tt aa} at level $l=2$. Note that the algorithm leaves a~pair of arcs $({\tt a}, {\tt aa}), ({\tt aa}, {\tt a})$ as they are needed to connect the component $\{{\tt aa}, {\tt aaa}\}$ to the rest of the solution. (d)~After processing the {\tt ae} node. The algorithm collapses all pairs of arcs for this node as it lies in the same component as a~node~{\tt c}. 
(e)~After processing the {\tt ca} node.
(f)~After processing the {\tt ec} node.
(g)~After processing the {\tt ee} node. Note that at this point the solution has exactly the same length as at the very beginning (at stage~(a)).
(h)~Finally, after collapsing all the unnecessary pairs of arcs from the level~$l=1$. The resulting solution is the same as constructed by the Greedy Hierarchical Algorithm (Figure~\ref{fig:hgexa}(c)).}
\label{fig:coll}
\end{figure}

\begin{figure}[h]
\begin{mypic}
\we{0}{0}{a}{
\foreach \f/\t/\a in {
eps/a/10,
a/aa/10,
aa/aaa/10,
aaa/aa/10,
aa/a/10,
a/eps/10,
eps/c/10,
c/ca/0,
ca/cae/0,
cae/ae/0,
ae/aec/0,
aec/ec/0,
ec/c/0,
c/eps/10,
eps/e/10,
e/ee/10,
ee/eee/10,
eee/ee/10,
ee/e/10,
e/eps/10
}
  \path (\f) edge[hgedge,bend left=\a,draw=black,thick] (\t);
}

\we{57}{0}{b}{
\foreach \f/\t/\a in {
eps/a/10, eps/a/20,
a/aa/10, a/aa/20,
aa/aaa/10, aa/aaa/20,
aaa/aa/10, aaa/aa/20,
aa/a/10, aa/a/20,
a/eps/10, a/eps/20,
eps/c/10, eps/c/20,
c/ca/0, c/ca/10,
ca/cae/0, ca/cae/10,
cae/ae/0, cae/ae/10,
ae/aec/0, ae/aec/10,
aec/ec/0, aec/ec/10,
ec/c/0, ec/c/10,
c/eps/10, c/eps/20,
eps/e/10, eps/e/20,
e/ee/10, e/ee/20,
ee/eee/10, ee/eee/20,
eee/ee/10, eee/ee/20,
ee/e/10, ee/e/20,
e/eps/10, e/eps/20
}
  \path (\f) edge[hgedge,bend left=\a,draw=black,thick] (\t);
}

\we{114}{0}{c}{
\foreach \f/\t/\a in {
eps/a/10, eps/a/20,
a/aa/10, a/aa/20, a/aa/30,
aa/aaa/10,
aaa/aa/10,
aa/a/10, aa/a/20, aa/a/30,
a/eps/10, a/eps/20,
eps/c/10, eps/c/20,
c/ca/0, c/ca/10,
ca/cae/0, ca/a/0,
cae/ae/0, a/ae/0,
ae/aec/0, ae/e/0,
aec/ec/0, e/ec/0,
ec/c/0, ec/c/10,
c/eps/10, c/eps/20,
eps/e/10, eps/e/20,
e/ee/10, e/ee/20,
ee/eee/10, ee/e/30,
eee/ee/10, e/ee/30,
ee/e/10, ee/e/20,
e/eps/10, e/eps/20
}
  \path (\f) edge[hgedge,bend left=\a,draw=black,thick] (\t);
}

\we{0}{-55}{d}{
\foreach \f/\t/\a in {
eps/a/10, eps/a/20, eps/a/30, eps/a/40, eps/a/50,
a/aa/10,
aa/aaa/10,
aaa/aa/10,
aa/a/10,
a/eps/10, a/eps/20, a/eps/30, a/eps/40, a/eps/50,
eps/c/10, eps/c/20, eps/c/30,
c/ca/0,
ca/cae/0,
cae/ae/0,
ae/aec/0,
aec/ec/0,
ec/c/0,
c/eps/10, c/eps/20, c/eps/30,
eps/e/10, eps/e/20, eps/e/30, eps/e/40, eps/e/50,
e/ee/10, 
ee/eee/10, 
eee/ee/10, 
ee/e/10, 
e/eps/10, e/eps/20, e/eps/30, e/eps/40, e/eps/50
}
  \path (\f) edge[hgedge,bend left=\a,draw=black,thick] (\t);
}

\we{57}{-55}{e}{
\foreach \f/\t/\a in {
eps/a/10, 
a/aa/10,
aa/aaa/10,
aaa/aa/10,
aa/a/10,
a/eps/10, 
eps/c/10, 
c/ca/0,
ca/cae/0,
cae/ae/0,
ae/aec/0,
aec/ec/0,
ec/c/0,
c/eps/10, 
eps/e/10, 
e/ee/10, 
ee/eee/10, 
eee/ee/10, 
ee/e/10, 
e/eps/10
}
  \path (\f) edge[hgedge,bend left=\a,draw=black,thick] (\t);
}


\end{mypic}
\caption{Stages of applying the Collapsing Algorithm to the dataset $\{{\tt aaa}, {\tt cae}, {\tt aec}, {\tt eee}\}$ and its \textbf{naive} solution resulting from overlapping the input strings in the same order as they are given. (a)~The solution of length 10 corresponding to the superstring {\tt aaacaeceee}. (b)~The doubled solution. (c)~After collapsing the $l=3$ level. (d)~After collapsing the $l=2$ level. (e)~After collapsing the $l=1$ level. The resulting solution is the same as constructed by the Greedy Hierarchical Algorithm (Figure~\ref{fig:hgexa}(c)).}
\label{fig:collnaive}
\end{figure}
\end{document}